{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个样本中，原始点云序列点总数ndataset=5*2\n",
      "经过FPS采样后，一个样本中点总数npoint=5*1\n",
      "new_time_时间差:\n",
      " [[[0. 0. 1. 1. 2. 2. 3. 3. 4. 4.]\n",
      "  [1. 1. 0. 0. 1. 1. 2. 2. 3. 3.]\n",
      "  [2. 2. 1. 1. 0. 0. 1. 1. 2. 2.]\n",
      "  [3. 3. 2. 2. 1. 1. 0. 0. 1. 1.]\n",
      "  [4. 4. 3. 3. 2. 2. 1. 1. 0. 0.]]]\n",
      "new_time_时间差取整:\n",
      " [[[0 0 1 1 2 2 3 3 4 4]\n",
      "  [1 1 0 0 1 1 2 2 3 3]\n",
      "  [2 2 1 1 0 0 1 1 2 2]\n",
      "  [3 3 2 2 1 1 0 0 1 1]\n",
      "  [4 4 3 3 2 2 1 1 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "#测试1：l0_time\n",
    "import tensorflow as tf\n",
    "batch_size=1\n",
    "num_point=2\n",
    "nsampoint=1\n",
    "num_frames=5\n",
    "print(\"一个样本中，原始点云序列点总数ndataset={}*{}\".format(num_frames,num_point))\n",
    "print(\"经过FPS采样后，一个样本中点总数npoint={}*{}\".format(num_frames,nsampoint))\n",
    "l0_time = tf.concat([tf.ones([batch_size, num_point, 1]) * i for i in range(num_frames)], \\\n",
    "            axis=-2) #shape(batch_size, ndataset, 1)  (1,3*2,1)  num_frames*num_point=ndataset\n",
    "new_time=tf.concat([tf.ones([batch_size, nsampoint, 1]) * i for i in range(num_frames)], \\\n",
    "            axis=-2)  #shape(batch_size, npoint, 1)  (1,3*1,1)   num_frames*nsampoint= npoint\n",
    "l0_time_reshape=tf.reshape(l0_time, [batch_size, 1, -1])  #(1,1,3*2)\n",
    "new_time_=tf.abs(l0_time_reshape-new_time)  #时间差：(1,3*1,3*2) (batch_size,npoint,dataset)\n",
    "cast_time=tf.cast(new_time_, tf.int32)  #new_time_值取整变为tf.int32类型\n",
    "with tf.Session() as sess:\n",
    "    #b=sess.run(l0_time)\n",
    "    #print(sess.run(l0_time))\n",
    "    #print(sess.run(l0_time_reshape))\n",
    "    print(\"new_time_时间差:\\n\",sess.run(new_time_))\n",
    "    print(\"new_time_时间差取整:\\n\",sess.run(cast_time))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=tf.ones([batch_size, num_point, 1]):\n",
      " [[[1.]\n",
      "  [1.]]]\n",
      "a*0=\n",
      "[[[0.]\n",
      "  [0.]]]\n",
      "a*1=\n",
      "[[[1.]\n",
      "  [1.]]]\n",
      "a*2=\n",
      "[[[2.]\n",
      "  [2.]]]\n"
     ]
    }
   ],
   "source": [
    "# #测试1：tf.ones([batch_size, num_point, 1]),及其*i\n",
    "# import tensorflow as tf\n",
    "# batch_size=1\n",
    "# num_point=2\n",
    "# num_frames=3\n",
    "# a=tf.ones([batch_size, num_point, 1])\n",
    "#\n",
    "# with tf.Session() as sess:\n",
    "#     print('a=tf.ones([batch_size, num_point, 1]):\\n',sess.run(a))\n",
    "#     for i in range(num_frames):\n",
    "#         print('a*{}=\\n{}'.format(i,sess.run(a*i)))   #a*i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间，一个样本帧数： 5\n",
      "RADIUS1: [0.5   0.525 0.55  0.575 0.6  ]\n",
      "RADIUS1[2:]=0之后: [0.5   0.525 0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "    #测试2:RADIUS1/2\n",
    "    import numpy as np\n",
    "    num_frames=5\n",
    "    print(\"时间，一个样本帧数：\",num_frames)\n",
    "    RADIUS1 = np.linspace(0.5, 0.6, num_frames, dtype='float32')#0.5开始，0.6结束，共num_frames多个数\n",
    "    #RADIUS2 = RADIUS1 * 2\n",
    "    print('RADIUS1:',RADIUS1)\n",
    "    #print('RADIUS2:',RADIUS2)\n",
    "    #测试radius[delta_t:]\n",
    "    delta_t=2\n",
    "    radius=RADIUS1\n",
    "    radius[delta_t:] = 0\n",
    "    print('RADIUS1[2:]=0之后:',RADIUS1)\n",
    "    # radius=RADIUS2\n",
    "    # radius[delta_t:] = 0\n",
    "    # print('RADIUS2[2:]=0之后:',RADIUS2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "令batch_size=1,即以一个样本，一个动态手势视频为例\n",
      "一个样本中，原始点云序列点总数ndataset=5*2\n",
      "经过FPS采样后，一个样本中点总数npoint=5*1\n",
      "时间，一个样本帧数： 5\n",
      "radius:\n",
      " [0.5   0.525 0.    0.    0.   ]\n",
      "sub_time:\n",
      " [[[0 0 1 1 2 2 3 3 4 4]\n",
      "  [1 1 0 0 1 1 2 2 3 3]\n",
      "  [2 2 1 1 0 0 1 1 2 2]\n",
      "  [3 3 2 2 1 1 0 0 1 1]\n",
      "  [4 4 3 3 2 2 1 1 0 0]]]\n",
      "radius_:\n",
      " [[[0.5   0.5   0.525 0.525 0.    0.    0.    0.    0.    0.   ]\n",
      "  [0.525 0.525 0.5   0.5   0.525 0.525 0.    0.    0.    0.   ]\n",
      "  [0.    0.    0.525 0.525 0.5   0.5   0.525 0.525 0.    0.   ]\n",
      "  [0.    0.    0.    0.    0.525 0.525 0.5   0.5   0.525 0.525]\n",
      "  [0.    0.    0.    0.    0.    0.    0.525 0.525 0.5   0.5  ]]]\n"
     ]
    }
   ],
   "source": [
    "#测试3：radius_=tf.gather(radius,\n",
    "print(\"令batch_size=1,即以一个样本，一个动态手势视频为例\")\n",
    "print(\"一个样本中，原始点云序列点总数ndataset={}*{}\".format(num_frames,num_point))#来自测试1\n",
    "print(\"经过FPS采样后，一个样本中点总数npoint={}*{}\".format(num_frames,nsampoint))#来自测试1\n",
    "print(\"时间，一个样本帧数：\",num_frames)  #来自测试2\n",
    "print('radius:\\n',radius)   #来自测试2：shape:num_frame ,32.本测试中是3\n",
    "cast_time=tf.cast(new_time_, tf.int32)   #时间差：来自测试1:shape:(batch_size,npoints,ndataset),其中npoints:32*32,ndataset=32*128. 测试中（1,3*1,3*2）\n",
    "sub_time=cast_time\n",
    "radius_=tf.gather(radius, sub_time)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"sub_time:\\n\",sess.run(sub_time))\n",
    "    print(\"radius_:\\n\",sess.run(radius_))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_xyz的shape: (1, 2, 3)\n",
      "new_xyz_expand的shape: (1, 2, 1, 3)\n",
      "new_xyz_tile的shape: (1, 2, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "#测试4:tf.expand_dims，tf.tile\n",
    "#new_xyz(batch_size, npoint, 3)  比如：npoint（32*32）就是32*32个采样点的3维坐标\n",
    "batch_size=1\n",
    "npoint=2\n",
    "nsample=5\n",
    "\n",
    "new_xyz=tf.zeros([batch_size,npoint,3])  #3\n",
    "new_xyz_expand=tf.expand_dims(new_xyz, 2)#3->(1,3)\n",
    "new_xyz_tile=tf.tile(tf.expand_dims(new_xyz, 2), [1, 1, nsample, 1]) #(1,3)->(nsample,3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ori=sess.run(new_xyz)\n",
    "    exp=sess.run(new_xyz_expand)\n",
    "    tile=sess.run(new_xyz_tile)\n",
    "    print(\"new_xyz的shape:\",ori.shape)\n",
    "    print(\"new_xyz_expand的shape:\",exp.shape)\n",
    "    print(\"new_xyz_tile的shape:\",tile.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2_0_dynamic\n",
      "W2_1_dynamic\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "   #print('conv%d' % (i))\n",
    "   #print('conv%d_dynamic' % i)\n",
    "   #print('W_%d_dynamic' % i)\n",
    "   #print('W1_%d_dynamic' % i)\n",
    "   print('W2_%d_dynamic' % i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "#测试5：flow_dim\n",
    "num_out_channel=256\n",
    "GROUP_SIZE=3\n",
    "flow_dim = num_out_channel // 2 // GROUP_SIZE * GROUP_SIZE + GROUP_SIZE\n",
    "print(flow_dim)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#测试6：测试tf.concat\n",
    "import tensorflow as tf\n",
    "batch_size=1\n",
    "npoint=9\n",
    "nsample=4\n",
    "\n",
    "a=4\n",
    "b=5\n",
    "out_channel=a\n",
    "new_points=tf.zeros([batch_size,npoint,nsample,out_channel])\n",
    "new_points_re=tf.reshape(new_points,[batch_size, -1, a])\n",
    "grouped_time=tf.zeros([batch_size,npoint,nsample,b])\n",
    "\n",
    "ccat1=tf.concat([new_points, grouped_time], -1)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"new_points.shape:\",sess.run(new_points).shape)\n",
    "    print(\"new_points_re.shape:\",sess.run(new_points_re).shape)\n",
    "    print(\"grouped_time.shape:\",sess.run(grouped_time).shape)\n",
    "    print(\"tf.concat结果的shape:\",sess.run(ccat1).shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export CUDA_HOME=$CUDA_HOME:/usr/local/cuda-11.0\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.0/lib64\n",
    "export PATH=$PATH:$CUDA_HOME/bin\n",
    "source ~/.bashrc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#测试7：normals_feat\n",
    "import tensorflow as tf\n",
    "batch_size=1\n",
    "npoint=2\n",
    "flow_dim=6\n",
    "GROUP_SIZE=3\n",
    "normals_feat=tf.zeros([batch_size,npoint,flow_dim // GROUP_SIZE,GROUP_SIZE]) #shape(1,2,2,3)\n",
    "b=tf.ones(shape=[batch_size, npoint, flow_dim // GROUP_SIZE, 1], dtype=normals_feat.dtype)#(1,2,2,1)\n",
    "c=tf.concat([normals_feat, -tf.ones(shape=[batch_size, npoint, flow_dim // GROUP_SIZE, 1], dtype=normals_feat.dtype)], -1)\n",
    "normals_feat=c\n",
    "normals_feat_final=tf.reshape(normals_feat, [batch_size, npoint, -1])\n",
    "with tf.Session() as sess:\n",
    "    print(\"normals_feat:【shape{}】\\n{}\".format(sess.run(normals_feat).shape,sess.run(normals_feat)))\n",
    "    print(\"b:【shape{}】\\n{}\".format(sess.run(b).shape,sess.run(b)))\n",
    "    #print(\"b.shape:\",sess.run(b).shape)\n",
    "    print(\"c:【shape{}】\\n{}\".format(sess.run(c).shape,sess.run(c)))\n",
    "    #print(\"c.shape:\",sess.run(c).shape)\n",
    "    print(\"normals_feat_final:【shape{}】\\n{}\".format(sess.run(normals_feat_final).shape,sess.run(normals_feat_final)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 2, 3],\n",
      "       [4, 5, 6]]), array([[ 7,  8],\n",
      "       [ 9, 10],\n",
      "       [11, 12]]), array([[ 58,  64],\n",
      "       [139, 154]])]\n"
     ]
    }
   ],
   "source": [
    "#测试8：tf.matmul\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
    "b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
    "c = tf.matmul(a, b)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([a,b,c]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-28ff62ded536>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mGROUP_SIZE\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mfea\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnpoint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGroup_num\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnsample\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mGROUP_SIZE\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#shape=[1, 2, 11, 64, 4]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[0mAtA\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfea\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfea\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtranspose_a\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0mnew_points_\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfea\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "#测试8：tf.matmul 5维矩阵 相乘维度\n",
    "#测试9：get_st_surface\n",
    "import tensorflow as tf\n",
    "batch_size=1\n",
    "npoint=2\n",
    "Group_num=11\n",
    "nsample=64\n",
    "GROUP_SIZE=3\n",
    "\n",
    "fea=tf.ones(shape=[batch_size, npoint, Group_num,nsample, GROUP_SIZE+1], dtype=b.dtype) #shape=[1, 2, 11, 64, 4]\n",
    "AtA=tf.matmul(fea, fea, transpose_a=True)\n",
    "new_points_=fea\n",
    "#feature matirx  shape=[1, 2, 11, 64, 4]\n",
    "duplicate_grouped_time=tf.ones(shape=[batch_size, npoint, Group_num,nsample, 1], dtype=b.dtype)\n",
    "#time  matirx    shape=[1, 2, 11, 64, 1]\n",
    "n_new_points_ = tf.matmul(new_points_, duplicate_grouped_time, transpose_a=True)\n",
    "with tf.Session() as sess:\n",
    "    sess.run([fea,AtA,new_points_,duplicate_grouped_time,n_new_points_])\n",
    "    print(\"duplicate_grouped_time.shape:\",duplicate_grouped_time.shape)\n",
    "    print(\"fea.shape:\",fea.shape)\n",
    "    print(\"AtA.shape:\",AtA.shape)\n",
    "    print(\"n_new_points_.shape:\",n_new_points_.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ust_data: \n",
      " [[[[ 1  2  3  4  5]\n",
      "   [ 6  7  8  9 10]\n",
      "   [11 12 13 14 15]\n",
      "   [16 17 18 19 20]]\n",
      "\n",
      "  [[21 22 23 24 25]\n",
      "   [26 27 28 29 30]\n",
      "   [31 32 33 34 35]\n",
      "   [36 37 38 39 40]]\n",
      "\n",
      "  [[41 42 43 44 45]\n",
      "   [46 47 48 49 50]\n",
      "   [51 52 53 54 55]\n",
      "   [56 57 58 59 60]]]]\n",
      "ust_data.shape: \n",
      " (1, 3, 4, 5)\n",
      "======================================\n",
      "ust_3:  [array([[[ 1,  6, 11, 16],\n",
      "        [21, 26, 31, 36],\n",
      "        [41, 46, 51, 56]]]), array([[[ 2,  7, 12, 17],\n",
      "        [22, 27, 32, 37],\n",
      "        [42, 47, 52, 57]]]), array([[[ 3,  8, 13, 18],\n",
      "        [23, 28, 33, 38],\n",
      "        [43, 48, 53, 58]]]), array([[[ 4,  9, 14, 19],\n",
      "        [24, 29, 34, 39],\n",
      "        [44, 49, 54, 59]]]), array([[[ 5, 10, 15, 20],\n",
      "        [25, 30, 35, 40],\n",
      "        [45, 50, 55, 60]]])]\n",
      "ust_3.length:  5\n",
      "ust_3.shape:  5  *  (1, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "#测试tf.unstack\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ust_data = np.arange(1, 61).reshape([1, 3, 4, 5])\n",
    "print('ust_data: \\n', ust_data)\n",
    "print('ust_data.shape: \\n', ust_data.shape)\n",
    "\n",
    "print('======================================')\n",
    "\n",
    "ust_3 = tf.unstack(ust_data, axis=3)\n",
    "ust_3 = sess.run(ust_3)\n",
    "print('ust_3: ', ust_3)\n",
    "print('ust_3.length: ', len(ust_3))\n",
    "print('ust_3.shape: ', len(ust_3), ' * ', ust_3[0].shape)       #  5 * (1, 3, 4) ==> (5, 2, 3, 4)\n",
    "\n",
    "\n",
    "# 理解：\n",
    "    # tf.unstack 其实是将axis维度直接放到最前面\n",
    "    # 也和 tf.transpose 类似\n",
    "#      总结：\n",
    "#     tf.unstack() 中 stacks = (维1，维2， 维3， 维4 ）\n",
    "#     当axis=0时， 就相当于tf.transpose(stacks, [0， 1， 2， 3])\n",
    "#     当axis=1时， 就相当于tf.transpose(stacks, [1， 0， 2， 3])\n",
    "#     当axis=2时， 就相当于tf.transpose(stacks, [2， 0， 1， 3])\n",
    "#     当axis=3时， 就相当于tf.transpose(stacks, [3， 0， 1， 2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W=last_W[:,:,0,:]的形状： (2, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "#测试W=last_W[:,:,0,:]是否会降维\n",
    "import tensorflow as tf\n",
    "last_W=tf.ones(shape=[2, 3, 4,5], dtype=b.dtype)\n",
    "W=last_W[:,:,0,:]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([last_W,W])\n",
    "    print(\"W=last_W[:,:,0,:]的形状：\",W.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsample=5,batch_size=2\n",
      "idx：\n",
      " [[[0 1 2 3 4]]\n",
      "\n",
      " [[0 1 2 3 4]]]\n",
      "idx的形状： (2, 1, 5)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#测试idx:方法sample_and_group_all的返回参数\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "nsample=5\n",
    "batch_size=2\n",
    "\n",
    "idx = tf.constant(np.tile(np.array(range(nsample)).reshape((1,1,nsample)), (batch_size,1,1)))\n",
    "with tf.Session() as sess:\n",
    "    print(\"nsample={},batch_size={}\".format(nsample,batch_size))\n",
    "    idx_t=sess.run(idx)\n",
    "    print(\"idx：\\n\",idx_t)\n",
    "    print(\"idx的形状：\",idx.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow1_list=[[1,2,3],[2,3]]\n",
    "len(flow1_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'last_flow1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-048dc52b1220>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mflow1_time\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlast_flow1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflow1_time\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'last_flow1' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "flow1_time=tf.ones(shape=[2, 3, 4,5], dtype=b.dtype)\n",
    "#tf.concat([last_flow1, flow1_time])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "44"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp=(11*4, )\n",
    "mlp[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:(1, 3, 6)\n",
      "[[[7 5 6 8 4 3]\n",
      "  [3 0 5 1 9 7]\n",
      "  [7 4 2 2 1 4]]]\n",
      "b:(1, 9, 2)\n",
      "[[[7 5]\n",
      "  [6 8]\n",
      "  [4 3]\n",
      "  [3 0]\n",
      "  [5 1]\n",
      "  [9 7]\n",
      "  [7 4]\n",
      "  [2 2]\n",
      "  [1 4]]]\n"
     ]
    }
   ],
   "source": [
    "#测试3维矩阵reshape\n",
    "import numpy as np\n",
    "\n",
    "a=np.random.randint(0,10,size=[1,3,3*2])\n",
    "print(\"a:{}\\n{}\".format(a.shape,a))\n",
    "b=a.reshape(1,-1,2)\n",
    "print(\"b:{}\\n{}\".format(b.shape,b))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathroot=os.path.dirname(__file__)#去掉文件名后的绝对路径\n",
    "path2data=os.path.join(pathroot,\"..\",\"data\",\"HPLFlowNet\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sudo apt-get --purge remove \"cuda*\"\n",
    "sudo apt-get --purge remove \"*nvidia*\"\n",
    "\n",
    "sudo apt-get install -y nvidia-docker2\n",
    "sudo systemctl restart docker\n",
    "vim ~/.bashrc\n",
    "source ~/.bashrc\n",
    "sudo apt-get install build-essential\n",
    "sudo apt-get install aptitude\n",
    "sudo aptitude install build-essential\n",
    "sudo tar -xvzf cudnn-11.2-linux-x64-v8.1.1.33.tgz\n",
    "sudo cp cuda/include/cudnn* /usr/local/cuda-11.2/include\n",
    "sudo cp cuda/lib64/libcudnn* /usr/local/cuda-11.2/lib64\n",
    "sudo chmod a+r /usr/local/cuda-11.2/include/cudnn*\n",
    "sudo chmod a+r /usr/local/cuda-11.2/lib64/libcudnn*\n",
    "cat /usr/local/cuda-11.2/include/cudnn.h\n",
    "python\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "torch.cuda.get_arch_list()\n",
    "torch.cuda.get_device_capability()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def changed_pointnet_sa_module(points, npoint, mlp, mlp2,  is_training, bn_decay, scope, bn=True, pooling='max', knn=False, use_xyz=True, use_nchw=False, freeze_bn=False,  trainable=True):\n",
    "    ''' changed PointNet Set Abstraction (SA) Module\n",
    "        Input:\n",
    "\n",
    "            points: (batch_size, ndataset, channel) TF tensor\n",
    "            npoint: int32 -- #points sampled in farthest point sampling\n",
    "\n",
    "            mlp: list of int32 -- output size for MLP on each point\n",
    "            mlp2: list of int32 -- output size for MLP on each region\n",
    "\n",
    "            use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n",
    "            use_nchw: bool, if True, use NCHW data format for conv2d, which is usually faster than NHWC format\n",
    "        Return:\n",
    "            new_points: (batch_size, npoint, mlp[-1] or mlp2[-1]) TF tensor\n",
    "    '''\n",
    "    data_format = 'NCHW' if use_nchw else 'NHWC' #NHWC\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        new_points = tf.expand_dims(points, 1) # (batch_size, 1, 32*16, 3)#points:(batch_size,32*16, 3)\n",
    "\n",
    "        # Point Feature Embedding\n",
    "        if use_nchw: new_points = tf.transpose(new_points, [0,3,1,2])\n",
    "        for i, num_out_channel in enumerate(mlp):\n",
    "            new_points = tf_util.conv2d(new_points, num_out_channel, [1,1],\n",
    "                                        padding='VALID', stride=[1,1],\n",
    "                                        bn=bn, is_training=is_training, trainable=trainable,\n",
    "                                        scope='conv%d'%(i), bn_decay=bn_decay,\n",
    "                                        data_format=data_format, freeze_bn=freeze_bn)\n",
    "            # data_format = 'NHWC' ，因为kernel_size[1,1], padding='VALID', stride=[1,1]\n",
    "            # 所以，shape中改变的只有C。\n",
    "            #new_points:shape(batch_size,1,32*16,mlp[-1])\n",
    "        if use_nchw: new_points = tf.transpose(new_points, [0,2,3,1])\n",
    "\n",
    "        # Pooling in Local Regions\n",
    "        if pooling=='max':\n",
    "            new_points = tf.reduce_max(new_points, axis=[2], keepdims=True, name='maxpool')\n",
    "            #shape(batch_size,1, 1,mlp[-1])\n",
    "            #比如mlp=[512, 1024],group_all=True,shape(batch_size,1, 1,1024)\n",
    "        elif pooling=='avg':\n",
    "            new_points = tf.reduce_mean(new_points, axis=[2], keepdims=True, name='avgpool')\n",
    "        elif pooling=='weighted_avg':\n",
    "            with tf.variable_scope('weighted_avg'):\n",
    "                dists = tf.norm(grouped_xyz,axis=-1,ord=2,keepdims=True)\n",
    "                exp_dists = tf.exp(-dists * 5)\n",
    "                weights = exp_dists/tf.reduce_sum(exp_dists,axis=2,keepdims=True) # (batch_size, npoint, nsample, 1)\n",
    "                new_points *= weights # (batch_size, npoint, nsample, mlp[-1])\n",
    "                new_points = tf.reduce_sum(new_points, axis=2, keepdims=True)\n",
    "        elif pooling=='max_and_avg':\n",
    "            max_points = tf.reduce_max(new_points, axis=[2], keepdims=True, name='maxpool')\n",
    "            avg_points = tf.reduce_mean(new_points, axis=[2], keepdims=True, name='avgpool')\n",
    "            new_points = tf.concat([avg_points, max_points], axis=-1)\n",
    "\n",
    "        # [Optional] Further Processing\n",
    "        if mlp2 is not None:\n",
    "            if use_nchw: new_points = tf.transpose(new_points, [0,3,1,2])\n",
    "            for i, num_out_channel in enumerate(mlp2):\n",
    "                new_points = tf_util.conv2d(new_points, num_out_channel, [1,1],\n",
    "                                            padding='VALID', stride=[1,1],\n",
    "                                            bn=bn, is_training=is_training, trainable=trainable,\n",
    "                                            scope='conv_post_%d'%(i), bn_decay=bn_decay,\n",
    "                                            data_format=data_format, freeze_bn=freeze_bn)\n",
    "            if use_nchw: new_points = tf.transpose(new_points, [0,2,3,1])\n",
    "\n",
    "        new_points = tf.squeeze(new_points, [2]) # (batch_size, npoints, mlp2[-1])\n",
    "        ##比如mlp=[512, 1024],group_all=True,shape(batch_size,1, 1024)\n",
    "\n",
    "        return  new_points\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r=1\n",
    "print(\"r=\"+r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
