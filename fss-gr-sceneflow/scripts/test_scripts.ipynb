{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# add path\n",
    "project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "from datasets.generic import Batch\n",
    "from models.scoop import SCOOP\n",
    "from tools.seed import seed_everything\n",
    "from tools.losses import compute_loss_unsupervised\n",
    "from tools.utils import log_string\n",
    "\n",
    "#测试1：scoop模型输入，1个batch是怎么样的？\n",
    "\n",
    "pathroot = os.path.dirname(__file__)#去掉文件名后的绝对路径\n",
    "path2data = os.path.join(pathroot, \"..\", \"data\", \"FlowNet3D\")\n",
    "path2data = os.path.join(path2data, \"kitti_rm_ground\")#KITTI:数据集所在路径\n",
    "\n",
    "\n",
    "from datasets.kitti_flownet3d import Kitti\n",
    "train_dataset = Kitti(root_dir=path2data, nb_points=2048, all_points=False,\n",
    "                      same_v_t_split=1, mode=\"train\")\n",
    "#train_dataset属性filename:包含了train/test/val各数据集中examples的文件（npz）路径。每个npz文件中包含3个数组，名字分别是['gt', 'pos2', 'pos1']。利用这些数组，每个npz对应一个dict={\"sequence\":List [pc1, pc2] ,\"ground_truth\":List [mask, flow]}\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=3,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        num_workers=0,#原本是8（多线程），调试时改为0\n",
    "        collate_fn=Batch,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#一个batch:{dict:3}.三个键至对是{\"sequence\":List [pc1, pc2] ,\"ground_truth\":List [mask, flow]，“orig_size”:List[example_pc_orig_size,example_pc_orig_size]\n",
    "#pc1,pc2,flow:{Tensor:(batch_size,nb_points,3)}   mask{Tensor:(batch_size,nb_points,1)}\n",
    "#example_pc_orig_size:{Tensor:(batch_size,1)}\n",
    "#batch_size:一个batch中有几个sample.(对应几个npz文件)\n",
    "for it, batch in enumerate(train_dataloader):\n",
    "    # Send data to GPU\n",
    "    batch = batch.to(device, non_blocking=True)\n",
    "    batch[\"sequence\"]\n",
    "    print(it)\n",
    "\n",
    "\n",
    "#**************KITTI类对象的方法load_sequence（）*****************\n",
    "# Load data:KITTI类对象的方法load_sequence（） （datasets/kitti_flownet3d.py）\n",
    "idx=0\n",
    "train_dataset.filename_curr = train_dataset.filenames[idx]\n",
    "with np.load(train_dataset.filename_curr) as data:\n",
    "    sequence = [data[\"pos1\"][:, (1, 2, 0)], data[\"pos2\"][:, (1, 2, 0)]]\n",
    "    ground_truth = [\n",
    "        np.ones_like(data[\"pos1\"][:, 0:1]),\n",
    "        data[\"gt\"][:, (1, 2, 0)],\n",
    "    ]\n",
    "\n",
    "# Restrict to 35m\n",
    "loc = sequence[0][:, 2] < 35\n",
    "sequence[0] = sequence[0][loc]\n",
    "ground_truth[0] = ground_truth[0][loc]\n",
    "ground_truth[1] = ground_truth[1][loc]\n",
    "loc = sequence[1][:, 2] < 35\n",
    "sequence[1] = sequence[1][loc]\n",
    "\n",
    "#**************KITTI类对象的方法load_sequence（）*****************\n",
    "#以上测试1：scoop模型输入，1个batch是怎么样的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pc [[1 1]\n",
      " [2 2]\n",
      " [3 3]\n",
      " [4 4]\n",
      " [5 5]]\n",
      "ind [0, 1, 3]\n",
      "pc: [[1 1]\n",
      " [2 2]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np#\n",
    "\n",
    "def key_frame_sampling(key_cnt, frame_size):\n",
    "    factor = frame_size * 1.0 / key_cnt\n",
    "    index = [int(j / factor) for j in range(frame_size)]\n",
    "    return index\n",
    "\n",
    "pc=np.array([[1,1],[2,2],[3,3],[4,4],[5,5]])\n",
    "print(\"pc\",pc)\n",
    "nbpoint=3\n",
    "ind =key_frame_sampling(5, nbpoint)  # list:从22个点均匀选nbpoint点，ind就是0-21中选出部分点的索引\n",
    "pc=pc[ind]\n",
    "print(\"ind\",ind)\n",
    "print(\"pc:\",pc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-c105d7af2543>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0ml\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"a\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "l=[\"a\"]\n",
    "torch.Tensor(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89599, 2799, 14, 2, 28, 10]\n"
     ]
    }
   ],
   "source": [
    "l=\"89599_2799_14_2_28_10\"\n",
    "l=l.split(\"_\")\n",
    "l=list(map(int,l))\n",
    "print(l)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
